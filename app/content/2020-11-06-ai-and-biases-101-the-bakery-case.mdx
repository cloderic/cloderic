---
title: 'AI & Biases 101: The bakery case'
date: 2020-11-06
canonicalUrl: 'https://thegoodai.co/2020/10/30/ai-and-biases-101-the-bakery-case/'
highlight: True
---

![Bakery Case](/content/2020-11-06-ai-and-biases-101-the-bakery-case/bakery-case.jpg)

As soon as AIs started to be deployed in the “real world”, they started to be
accused of being biased. Are AIs inherently racist or misogynistic, do they
always support the status quo ? Recently, while exposing a weird background
detection “bug” in Zoom resulting in the erasure of his black colleague’s head,
[Colin Madland](https://twitter.com/colinmadland) found out a similar issue in
[Twitter picture cropping algorithm](https://twitter.com/colinmadland/status/1307111816250748933?s=20).

As always, the debate raged between people denouncing the bias in the algorithm
and those stating the development team reproduced their own biases. In this
article, I want to help you understand how AIs end up reproducing such biases
and what can be done about that.

[Read the full article at **The Good AI**](https://thegoodai.co/2020/10/30/ai-and-biases-101-the-bakery-case/)
